### 文本纠错方案

问题：目前我们的OCR模型，对印刷中文的识别准确度已经较高，还存在的错误类型有：1）不等长错误：漏字，多字；2）字符等长下，中文字型发生混淆；3）符号和英文问题。其中以字形混淆为主

策略：引入错别字纠错模型

* 如何定位错别字？
  * 方案一：用两个异构模型的预测结果做字符比较。可信度较高；模型庞大，速度下降
  * 方案二：利用网络输出的字符置信度，判断错别字位置。可行度较低，单模型方便
* 定位错字后如何纠正？
  * 方案一：直接利用bert训练的NLP纠错模型，可以省略定位的步骤，但效果一般，有会增加模型大小
  * 方案二：生成中文字符的混淆字典；利用n-grams模型统计训练集中字符组合的概率；模型简单。



### 错别字定位

利用方案二，主要解决汉字字形错误的问题，做如下假设：

* 假设模型发生漏字，多字的情况较少；
* 预测的字符串和真实结果绝大部分都是等长的；
* 在字符等长情况下只考虑中文汉字的字形错误；

#### 算法步骤

* 收集带标签的测试集，统计预测正确的样本（完全匹配必然等长），和预测错误的样本

* 在错误样本中，过滤预测不等长的样本；统计（不等长占比，可视为误差改善的上限）

* 统计所有等长预测中，**逐个字符的对应的结果** [gt  pred  confidence]

  * 划分正负样本，设定置信度阈值，计算字符的P-R值
  * 部分TP会变成FN，给纠错带来负作用，同时会降低召回率（需要避免过小）
  * 部分TN会变成FP，相当于漏检，会降低准确率，但对纠错没有影响
  * P-R值的目标希望准确率和召回率都高

* 另外可以统计单字符的正负样本，计算其P-R值。划分难易识别的字符集（也可以用样本频率来收集）

  * 如果某个字符TP少，则其P-R都会小，划分为难训练样本；
  * 如果FN多说明大量预测成其他字符（R值小，单一的源，预测成各类字符）
  * 如果FP多说明有大量的其他字预测成该字（P值小）
  * 如果P-R值都比较高则划分为容易训练的样本

* 统计总体样本中的字符频率来划分难易样本：

  >1.假设总的样本中字符的分布可知；
  >
  >2.训练集和测试集都对总样本有一个很好的估计（有偏）
  >
  >3.训练集中需要识别稀少字符，其分布有一个“肥尾”（平衡字符数量）

* 得到难易字符样本可以用来评价模型对字符的识别能力；并有针对性地对一些难识别的字符进行后处理