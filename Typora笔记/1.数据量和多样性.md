1.数据量和多样性

​	2.丰富的预料，在线增强训练

​	3.单一场景多合成真实场景的数据

​	* kw级别，在选增强数倍

​	

* 



交流的问题：

核心建议：数据瓶颈，在训练增强真实图片，他们那边kw级别，丰富语料；对于模糊图片的问题；没有做，也是用增强。对于稀少字的解决方法，也是用数据增强解决，没有后处理；检测的目前采用分割算法，DB和corner都是不错的选择，（雷钧的模型，复线不了，不在更新）





* 模型后处理，没有后处理
* 学习率等等调整对最终的效果影响不大，还是数据影响更大
* backbone-等等影响差别不大
* 用经典的CRNN









检测这一块：

算法选择：

​	db召回率比较低；基于**分割的算法**做比较新

​    corner：标注麻烦

检测数据量：

​	单一场景，几百张-k级别



印章问题比较麻烦

表格还原问题



训练工具-性能优化工具



计划的点

DB算法实现接入模型：4/16日；

* 设计在线增强的方法，blur，噪声等（归类模糊情况等）；4/16日实现在线增强
* 统计字符平衡度，对不平衡字符进行重复增强
* 收集预料，合成对应的字符（合成方法-实际场景接近程度-字体-间距-扭曲等）
* 实现DB检测算法； 4/16日
* 调试检测大小图的适应度，优化DB较低召回率的问题  4/23

 

从1800张挑出多样的200张作为债券检测-识别的标准测试集；截取其中的小图XX张作为另一个测试集