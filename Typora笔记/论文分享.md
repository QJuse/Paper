### JOINT CTC-ATTENTION BASED END-TO-END SPEECH RECOGNITION

来源：17

#### 背景和思路

attention模型，不基于条件独立性假设，利用了历史的预测信息，其性能通常比CTC模型好。但实践观测到attention模型在有噪声的情况下效果差，且对于长文本在开始的时候很难训练。

一种解释是：attention模型在对齐时过于灵活，缺少像CTC一样固定的约束。因此论文提出将CTC和Attention损失结合的方法，缓解对齐问题，来提高**模型的“鲁棒性”和快速收敛性**。



#### 算法关键点

关键是理解CTC和Attention文本识别的公式，论文就是将两个loss结合起来，联合损失中CTC损失取0.2是比较好的实验结果。

![1593655610031](C:\Users\viruser.v-desktop\AppData\Roaming\Typora\typora-user-images\1593655610031.png)

<img src="C:\Users\viruser.v-desktop\AppData\Roaming\Typora\typora-user-images\1593655568337.png" alt="1593655568337" style="zoom:67%;" />



### Aggregation Cross-Entropy for Sequence Recognition

来源：17