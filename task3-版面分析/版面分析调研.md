[TOC]

## 版面分析调研

### 计划问题

* 定义版面分析的问题需求
* 调研相关数据集，主流的模型方法      | 1周
* 选择求解问题的模型方案，跑通baseline方法     | 1周
* 模型改进优化   | 2~3周





### 基本概念

* **文档布局分析 (Document Layout Analysis)**

  >**识别并分类文档图像中的感兴趣区域**。**几何布局分析**：检测并标记文本正文，插图，数学符号和嵌入的表格等不同区域；**逻辑布局分析**：检测并标记文本区域在文档中扮演的逻辑角色（标题，标题，脚注等）

* 文档分析需求：

  * 自动分析并处理文档图像的各个区域
  * 自动检测并定位文档图片上的重要对象（文字，表格，数字公式等）

* 解决方案设计：

  * 数据集：2000张样本；BBox位置标注；**Mask掩膜标注**

    > 区域类别：文本|图片|表格；  
    >
    > 逻辑类别：标题 | 页眉 | 页脚 | Logo | 图片 | 表格 | 段落文本

  * 模型方案：1）图像分割的方法（Segmentation） 2）边框回归的方法（BBox）

    >分割方法：有基于图论、基于像素聚类和基于深度语义方法这三大类

    * Backbone网络 + 反卷积/上采样预测高精度结果图
    *  Mask-R-CNN， FCN， Fast-R-CNN， YOLO等

>A
>
>In order to create general page segmentation method without using any prior knowledge of the layout structure of the documents, we consider the page segmentation problem as
>a pixel labeling problem. We propose to use a CNN for the pixel labeling task





### Blogs|Papers|Codes|资源

#### Papers: 包括大量图像分割

* [An adaptive over-split and merge algorithm for page segmentation](https://www.sciencedirect.com/science/article/abs/pii/S0167865516301350?via%3Dihub) | 2016

* [Text-Line Detection in Camera-Captured Document Images Using the State Estimation of Connected Components](http://www.ncbi.nlm.nih.gov/pubmed/27623582) | 2016

* [Encoder-Decoder-with-Atrous-Separable-Convolution-for-Semantic-Image-Segmentation]()  | 2018 | OK

  >[博客1](https://www.cnblogs.com/fourmi/p/9864510.html) [博客2](https://blog.csdn.net/u010067397/article/details/86505795)

* Text and non-text separation in offline document images: a survey

* [Classification of Document Page Images.pdf](https://github.com/wanghaisheng/awesome-ocr/files/1954226/Classification.of.Document.Page.Images.pdf)

  [Phd_Thesis_Document Image Classification Combining Textual and Visual Features](https://github.com/wanghaisheng/awesome-ocr/files/1954229/Phd_Thesis_Nocelucia_completa.pdf)
  [Document Image Classification on the Basis of Layout Information.pdf](https://github.com/wanghaisheng/awesome-ocr/files/1954238/Document.Image.Classification.on.the.Basis.of.Layout.Information.pdf)

#### Blogs

* [UI2CODE工程--版面分析](https://zhuanlan.zhihu.com/p/58018937)  | 2019 | @

  > 前后景分离算法：找到背景的连通区域和闭合区间；
  >
  > 1.判断纯色和渐变色背景区块，通过sobel，Lapacian，canny等算子计算出梯度变化的方向
  >
  > 2.渐变色背景优化：基于**漫水填充算法**，选取漫水的种子节点，滤除渐变色背景区域噪声

* [宜信OCR技术探索之版面分析业务实践|技术沙龙直播速记](https://blog.csdn.net/gao2175/article/details/108470609?utm_medium=distribute.pc_relevant.none-task-blog-title-3&spm=1001.2101.3001.4242) | 2020  | @@@

  * [视频地址](https://v.qq.com/x/page/i3135lgkagd.html)

    >1.抽象行列识别：对检测框进行行列组合，是版面还原的基础。1）用纵坐标判断所属行；2）数据投影方法；3）方块组合
    >
    >2.模板开发：业务类 -->大类-->模板。例如同是A公司债券文档的大类，根据无线表，有线表等不同模板。模板的使用在具体业务中比较灵活。
    >
    >3.结构化难点：
    >
    >1）水印和印章干扰；
    >
    >2）单元格隔行；无标题数据；标题分多行；
    >
    >3） 检测结果相近行列发生粘连；检测缺块
    >
    >4.语义校正: 利用NLP模型纠正错别字

* [OCR技术 之 Layout Analysis](https://blog.csdn.net/zxs0222/article/details/104436014?utm_medium=distribute.pc_relevant.none-task-blog-title-10&spm=1001.2101.3001.4242)  | 2020 | @

  >版面分析：在OCR识别之前对页面板块进行划分，有助于提高对复杂页面的准确率。
  >
  >1.版面划分：1）同质内容；2）矩形框划分方法；
  >
  >2.版面分割：
  >
  >​	自顶向下逐步将文档分割成块：连通体分析、游程合并算法（RLAS）、基于背景分析法
  >
  >​	自底向上则找连通域（结构复杂缺少先验知识）：投影分析（X-Y algorithm）



* [走进AI时代的文档识别技术 之文档重建](https://blog.csdn.net/Tencent_TEG/article/details/92857138?utm_medium=distribute.pc_relevant_download.none-task-blog-blogcommendfrombaidu-4.nonecase&depth_1-utm_source=distribute.pc_relevant_download.none-task-blog-blogcommendfrombaidu-4.nonecas) | 2019 |@@@

  >我们针对版面分析、表格重建痛点问题，利用端到端深度学习模型对文档图像进行语义分割，进而提取结构化的语义信息; 针对表格重建，我们同时引入CNN提取表格边线，免去许多复杂后处理流程。系统首先对包含文档的图像进行检测，对扭曲的文档进行校正。然后通过版面分析模块，得到段落、图表等兴趣区域，针对每个区域进行相应增强恢复处理。最后根据阅读顺序，生成用户可以直接编辑的电子文档
  >
  >1.输入模块分为自动框选和扭曲矫正两个步骤。利用HED深度学习模型自动框选图片中的文档区域，扭曲矫正算法利用DocNet深度学习模型对文档图片进行扭曲矫正。
  >
  >2.版面分析模块利用了图像分割模型UNet对文档版面进行学习
  >
  >3.排版模块根据版面信息生成最终的word文档， 对于文字类型的子块，组段算法是利用OCR技术对文字块图片的文字信息进行组段； 对于表格类型的子块，运用图像分割对表格框线像素进行识别，再结合OCR文本框坐标关系，推断出单元格的位置，最后对单元格内容进行分析，进一步得到单元格字号和对齐方式；对于图片、公式类型，直接切图输出图片；根据子块的位置、语义信息，复原文档的阅读排序。

  >针对版面分析、字体识别以及扭曲校正等任务，我们设计了一套文档仿真系统。解决依赖大量的数据样本的问题。用户可以自定义字体类型、字号大小、图表数量大小、版面类型等属性，生成复杂多样的文档数据，同时**自动对其进行标注**，极大减少采集和标注数据的成本。

  >**版面分析网络**：为了让网络得到较大的感受野，会对特征图进行下采样，导致丢失很多边缘细节信息，得到的物体边界轮廓往往不够清晰。我们提出了端到端多尺度融合模型如图，主要由两部分组成：编码器和解码器，相同尺度的编码器特征和解码器特征会相互结合，这样同时保持了语义特征和边缘特征。为了加速网络的学习，让低层的特征学习到框线表示，这里我们引入多尺度模型融合，编码器每个部分都有相应的预测输出，融合解码器的输出作为最终的结果。
  >
  >为了加快网络各个特征层的学习我们引入**多尺度损失函数融合**，分别计算原图分辨率下的损失函数, 原图1/4和原图1/16的损失函数，最后将这三个结果融合作为我们的目标函数。特别指出的是，在文档版面中公式、表格的占比远远少于段落文字，存在严重类别不均衡问题。传统语义分割损失函数往往采用交叉熵，针对类别不均衡效果不太理想，对于公式这种数据较少的类别识别效果很差。因此我们这里引入IOU 损失函数，它能很好的解决类别不均衡问题。

* [文档识别技术回顾与反思](https://blog.csdn.net/moxibingdao/article/details/106667342?utm_medium=distribute.pc_relevant_download.none-task-blog-blogcommendfrombaidu-1.nonecase&depth_1-utm_source=distribute.pc_relevant_download.none-task-blog-blogcommendfrombaidu-1.nonecas)  | 2019 | @@@

  >图像预处理：增强去噪  | 二值化 | 校正
  >
  >版面分析：区域和文本线划分 | 投影XY | 递归XY切分 |
  >
  >场景文本检测：任意形状文本检测
  >
  >文本识别： 手写中文字符 | 公式识别

  <img src="C:\Users\viruser.v-desktop\AppData\Roaming\Typora\typora-user-images\1604320980644.png" alt="1604320980644" style="zoom:67%;" />

<img src="C:\Users\viruser.v-desktop\AppData\Roaming\Typora\typora-user-images\1604321103652.png" alt="1604321103652" style="zoom: 67%;" />



* [OCR技术浅探：特征提取(1)](https://blog.csdn.net/weixin_30252155/article/details/97870509?utm_medium=distribute.pc_relevant_download.none-task-blog-blogcommendfrombaidu-2.nonecase&depth_1-utm_source=distribute.pc_relevant_download.none-task-blog-blogcommendfrombaidu-2.nonecas) | 2017

  * 完整的OCR系统分为“特征提取”、“文字定位”、“光学识别”、“语言模型”四个方面**，逐步进行解决，最终完成了一个可用的、完整的、用于印刷文字的OCR系统

  * 文字部分的特征假设：

    > 要识别的图像字体都是比较规范的印刷字体，如宋体、黑体、楷体、行书等
    >
    > 文字与背景应该有比较明显的对比度；假设了图片文本是横向排版的；
    >
    > 文字的笔画应该有一定的宽度，不可以太细；同一个文字的色彩应该最多是渐变的；
    >
    > 一般文字是通过比较密集的笔画成字的，并且很多时候都具有一定的连通性

  * 特征提取

    >希望找出图像中候选的文字区域特征。传统的文本分割思路大多数是“边缘检测 + 腐蚀膨胀 + 联通区域检测”。我们通过聚类、分割、去噪、池化等步骤，得到了比较良好的文字部分的特征。
    >
    >* 将原始图片以灰度图像的形式读入
    >* 图像放大：直接处理，则会导致文字笔画过小，容易被当成噪音处理掉；使用插值算法来填补空缺部分的像素，导致文字与背景之间的区分度降低
    >* 对图像的色彩进行聚类：**灰度分辨率**   肉眼的灰度分辨率大概为40；聚类是根据图像的特点自适应地进行多值化的过程，避免了传统的简单二值化所带来 的信息损失：灰度统计+  结果平滑化的方法=核密度估计。
    >* **逐层识别**：通过逐层处 理的方式找出图像中的文字区域。定义了连通区域后，每个图层被分割为若干个连通区域，也就是说，我们 逐步地将原始图像进行分解
    >* **抗腐蚀测试** 文字所在的连通区域应当具有一定的抗腐蚀能力。连通区域的抗腐蚀能力 = 该区域被腐蚀后的总面积/该区域被腐蚀前的总面积 (7)
    >* 特征整合：文字可能分布在多个特征层，因此需要对特征层进行整合；直接叠加特征，然后对叠加特征划分连通区域；检测每个连通区域的主要贡献是哪个特征层，该连通区域就只保留这个特征层的来源
    >
    >



https://github.com/wanghaisheng/awesome-ocr/issues/86





### 中文Paper摘要

* [基于Mask R-CNN的满文文档版面分析](http://www.wanfangdata.com.cn/details/detail.do?_type=perio&id=dlmzxyxb201903010) | 期刊|·|2019 | 知网  | @@

  本文使用Mask R-CNN对满文文档进行版面分析，转换为图像实例分割的问题；使用ResNet101网络和FPN网络提取满文文档图像特征，特征图经过RPN网络和RoI Align层生成新的特征图；通过全连结分支对区域的分类和边框预测，使用mask预测,最终实现满文文档图像的实例分割

  > 图像分割方法：Mask R-CNN



* [非结构化文档的版面分析及表格提取](http://cdmd.cnki.com.cn/Article/CDMD-10004-1019190330.htm)  **|硕士论文|北京交通大学|2019 | 知网  | @@@**

  本论文采用 Faster R-CNN网络，图像投影计算的算法，对文档图像进行版面内容的**自动分类与定位**（版面分析），对表格进行识别提取和转换（表格识别），实现非结构化的图像文档向结构化文档转换。

  ​		**版面分析**：1）半结构化图片的转换 ？并对图片进行投影计算； 2）图像处理算法和模式识别方法，对各版面组成部分进行分类和初步定位；3）不确定的情况再用Faster R-CNN的方法进行分析。使用mAP评价分类和定位效果。 结果71.3%

  > 传统方法+Fast RCNN检测: 控制计算量，减小数据集规模

  ​		**表格识别**：1）图片去噪，倾斜校正，去遮挡；2）对提取出的表格细化类型，全线表格、纯横线表格、色彩相间表格以及无线表格分别进行处理和算法设计；3）切分表格单元，OCR识别，Excel表格内容复现。使用表格识别及转换率评价效果。结果81%。

  >分别设计表格提取算法，推测是传统算法

  

* [多特征融合的文档图像版面分析](http://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFD&filename=ZGTB202002009)  **| 期刊|中国图象图形学报|2020 | 知网  | @@@**

  文档图像版面分析,主流的深度学习能同时实现**版面的定位与分类**。本文采用多特征融合的方法，1）采用不同大小的卷积核并行对输入图像提取特征，再组成融合的特征；2）采用Deeplab V3的空间金字塔策略，添加图像级特征对提取的特征图进一步优化；3）通过双线性插值法对图像进行恢复，完成文档版面目标的定位与识别任务。通过mIOU和PA(像素精度)评价算法效果。87. 26%和98. 10%。

  > 图像分割方法： 对比FCN和Deeplab V3方法



* [文混编图像的版面分析及识别研究](http://cdmd.cnki.com.cn/Article/CDMD-10361-1019110836.htm) |硕士论文|安徽理工大学 | 2019 | 知网    |  @

  本文(1)提出了融合轮廓投影的连通域版面分割算法。先对图文混编图像进行预处理,再基于八连通将整个图文混编图像进行单字区域扩充。然后根据轮廓投影后的灰度直方图中波形的规律性和周期性对不同区域进行大致划分。最后通过引入文本行(列)间隔阈值以及图文间隔阈值对各个连通区域进行合并。

  > 传统方法：人工设计特征

  OCR单字符识别：1）分区域进行OCR识别，该算法对标题汉字采用36×36点阵归一化处理,首先对标题汉字进行粗划分,根据绝对值距离,从字典库7000个汉字中选出与标题汉字匹配的前m个汉字。然后对标题汉字进行细划分,根据欧氏距离,从m个汉字中选出匹配的前n(nm)个汉字。2）研究了基于局部特征的SIFT算法的图像匹配技术

  > 使用汉字匹配方法



* [基于支持向量机的版面分割问题研究](http://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFD&filename=XDDJ202002038)  | 期刊|现代电子技术|2020 | 知网  | @

  文中将相位一致性统计特征和改进灰度共生矩阵的纹理特征相结合,得到一种新的组合特征向量。将该组合特征向量作为训练样本,最终得到基于支持向量机的复杂图像分割算法。

  > 传统方法：人工设计特征+ SVM







### 数据集和比赛

* ICDAR 2017 POD文档版面，目标检测数据集

* PubLayNet数据集

  * 大型文档图像版面分析的数据集，采用多边形边框分割标注。超过36万个文档图像，预训练的模型也可以在不同文档域上进行转移学习。文档的来源是PubMed Central Open Access子集（商业用途集合）。通过匹配PubMed Central Open Access子集中的文章的PDF格式和XML格式，自动生成注释。
* [paper地址](https://arxiv.org/pdf/1908.07836.pdf) | 数据获取：关注微信公众号 datayx  然后回复  **版面分析**
  
* Tobacco3482 dataset

  * [http://www.cs.cmu.edu/%7Eaharley/rvl-cdip/](http://www.cs.cmu.edu/~aharley/rvl-cdip/)
  * ![1604374930442](C:\Users\viruser.v-desktop\AppData\Roaming\Typora\typora-user-images\1604374930442.png)

* CODES   https://github.com/wanghaisheng/awesome-ocr/issues/86

  * https://github.com/PiSchool/enterprise-document-classification
    https://github.com/jcbgamboa/autodoc

  * https://github.com/DIVA-DIA/LayoutAnalysisEvaluator

    [LayoutEvaluation_1.8.129.zip](https://github.com/wanghaisheng/awesome-ocr/files/2035163/LayoutEvaluation_1.8.129.zip)
    [Layout Evaluation User Guide.pdf](https://github.com/wanghaisheng/awesome-ocr/files/2035164/Layout.Evaluation.User.Guide.pdf)
    http://www.primaresearch.org/tools/PerformanceEvaluation

  * http://www.mdpi.com/2313-433X/3/4/62/htm

    https://github.com/DocCreator/DocCreator

  * https://github.com/frotms/line_detector

  * EDLines: Edge Drawing (ED)-Based Real-Time Line Segment Detection

  * https://github.com/linuxlizard/page_segmentation

  * https://github.com/fascarzacs/historicalDocumentsPageSegmentation

  * https://github.com/RaymondMcGuire/BOOK-CONTENT-SEGMENTATION-AND-DEWARPING

  * https://github.com/majeek/scribbleSegmentation

Papers

https://github.com/wanghaisheng/awesome-ocr/issues/86

